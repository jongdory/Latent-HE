{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, importlib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import _pickle as cPickle\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import CustomTest\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "def get_obj_from_str(string, reload=False):\n",
    "    module, cls = string.rsplit(\".\", 1)\n",
    "    if reload:\n",
    "        module_imp = importlib.import_module(module)\n",
    "        importlib.reload(module_imp)\n",
    "    return getattr(importlib.import_module(module, package=None), cls)\n",
    "\n",
    "def instantiate_from_config(config):\n",
    "    if not \"target\" in config:\n",
    "        raise KeyError(\"Expected key `target` to instantiate.\")\n",
    "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataset list to txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = []\n",
    "chex_root = \"CheXpert\"\n",
    "\n",
    "for root, dirs, files in os.walk(chex_root):\n",
    "    for file in files:\n",
    "        if file.endswith(\".png\") or file.endswith(\".jpg\"):\n",
    "            data_paths.append(os.path.join(root, file))\n",
    "            \n",
    "with open(\"data/chexpert.txt\", \"w\") as f:\n",
    "    for path in data_paths:\n",
    "        f.write(path + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"configs/cxr_f8_vqgan.yaml\"\n",
    "config = OmegaConf.load(base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load VQGAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = instantiate_from_config(config.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save latent and label to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_dict = {\"Enlarged Cardiomediastinum\": 0, \"Cardiomegaly\": 1, \"Lung Opacity\": 2, \"Lung Lesion\": 3,\n",
    " \"Edema\": 4, \"Consolidation\": 5, \"Pneumonia\": 6, \"Atelectasis\": 7, \"Pneumothorax\": 8, \n",
    " \"Pleural Effusion\":9 , \"Pleural Other\": 10, \"Fracture\": 11, \"Support Devices\": 12, \"No Finding\": 13}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = f\"data/chexpert.txt\"\n",
    "dataset = CustomTest(size=256, test_images_list_file=data_list)\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=8)\n",
    "\n",
    "chex_train = pd.read_csv('CheXpert/train_visualCheXbert.csv')\n",
    "\n",
    "chex_train['Path'] = chex_train['Path'].apply(lambda x: x.split('CheXpert-v1.0/')[-1])\n",
    "\n",
    "vq_list = {}\n",
    "fs = 8\n",
    "dataname = \"chexpert\"\n",
    "filename = f'{dataname}_{fs}.pkl'\n",
    "\n",
    "model = model.cuda()\n",
    "with open(filename, 'wb') as f:\n",
    "    for data in data_loader:\n",
    "        file_path_ = data['file_path_'][0].split(' ')[0]\n",
    "        image_index = file_path_.split('chexpert/')[-1]\n",
    "        \n",
    "        if \"frontal\" not in image_index: continue\n",
    "        if image_index not in chex_train['Path'].values: continue\n",
    "\n",
    "        label = []\n",
    "        for key in cls_dict.keys():\n",
    "            if chex_train[chex_train['Path'] == image_index][key].values[0] == 1:\n",
    "                label.append(cls_dict[key])\n",
    "\n",
    "        image = data['image']\n",
    "        image = image.permute(0, 3, 1, 2).cuda()\n",
    "        latent = model.encoder(image).cpu().detach().numpy().squeeze()\n",
    "\n",
    "        vq_list[image_index] = {'latent': latent, 'label': label}\n",
    "        break\n",
    "\n",
    "    print(\"save latent to\", filename)\n",
    "    cPickle.dump(vq_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cpu()\n",
    "\n",
    "h = torch.tensor(latent).unsqueeze(0)\n",
    "h = model.quant_conv(h)\n",
    "quant, _, _ = model.quantize(h)\n",
    "quant = model.post_quant_conv(quant)\n",
    "recon = model.decoder(quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(image[0].permute(1, 2, 0).detach().cpu().numpy())\n",
    "ax[1].imshow(recon[0].permute(1, 2, 0).detach().cpu().numpy())\n",
    "\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "ax[0].set_title(\"original\")\n",
    "ax[1].set_title(\"recon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
